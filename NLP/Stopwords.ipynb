{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb75549f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Speech Of DR APJ Abdul Kalam\n",
    "paragraph = \"\"\"I have three visions for India. In 3000 years of our history, people from all over \n",
    "               the world have come and invaded us, captured our lands, conquered our minds. \n",
    "               From Alexander onwards, the Greeks, the Turks, the Moguls, the Portuguese, the British,\n",
    "               the French, the Dutch, all of them came and looted us, took over what was ours. \n",
    "               Yet we have not done this to any other nation. We have not conquered anyone. \n",
    "               We have not grabbed their land, their culture, \n",
    "               their history and tried to enforce our way of life on them. \n",
    "               Why? Because we respect the freedom of others.That is why my \n",
    "               first vision is that of freedom. I believe that India got its first vision of \n",
    "               this in 1857, when we started the War of Independence. It is this freedom that\n",
    "               we must protect and nurture and build on. If we are not free, no one will respect us.\n",
    "               My second vision for India’s development. For fifty years we have been a developing nation.\n",
    "               It is time we see ourselves as a developed nation. We are among the top 5 nations of the world\n",
    "               in terms of GDP. We have a 10 percent growth rate in most areas. Our poverty levels are falling.\n",
    "               Our achievements are being globally recognised today. Yet we lack the self-confidence to\n",
    "               see ourselves as a developed nation, self-reliant and self-assured. Isn’t this incorrect?\n",
    "               I have a third vision. India must stand up to the world. Because I believe that unless India \n",
    "               stands up to the world, no one will respect us. Only strength respects strength. We must be \n",
    "               strong not only as a military power but also as an economic power. Both must go hand-in-hand. \n",
    "               My good fortune was to have worked with three great minds. Dr. Vikram Sarabhai of the Dept. of \n",
    "               space, Professor Satish Dhawan, who succeeded him and Dr. Brahm Prakash, father of nuclear material.\n",
    "               I was lucky to have worked with all three of them closely and consider this the great opportunity of my life. \n",
    "               I see four milestones in my career\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88f7d16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4549d003",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\vedan\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\vedan\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\vedan\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import ssl\n",
    "import os\n",
    "\n",
    "# Handle SSL issues that can prevent downloads on Windows\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "# Download to user's nltk_data directory\n",
    "download_dir = os.path.join(os.path.expanduser('~'), 'nltk_data')\n",
    "os.makedirs(download_dir, exist_ok=True)\n",
    "\n",
    "nltk.download('stopwords', download_dir=download_dir)\n",
    "nltk.download('punkt', download_dir=download_dir)\n",
    "nltk.download('punkt_tab', download_dir=download_dir)  # Required for newer NLTK versions\n",
    "\n",
    "# Add to NLTK data path\n",
    "nltk.data.path.append(download_dir)\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73f84126",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = nltk.tokenize.sent_tokenize(paragraph, language='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13d290f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Apply stopwords and filter , and then apply stemming\n",
    "from nltk.tokenize import word_tokenize\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    tokens = word_tokenize(sentences[i])                 # tokenize into words\n",
    "    tokens = [t.lower() for t in tokens]                 # normalize to lowercase\n",
    "    filtered = [t for t in tokens if t.isalpha() and t not in stop_words] # removes non purely alphabetic words\n",
    "    stemmed = [stemmer.stem(t) for t in filtered]\n",
    "    sentences[i] = ' '.join(stemmed)  # convert back to a processed sentence\n",
    "\n",
    "## Iterating thru each sentence --> tokenizing into words --> filter stopwords --> stemming --> store back\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18ff6339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['three vision india',\n",
       " 'year histori peopl world come invad us captur land conquer mind',\n",
       " 'alexand onward greek turk mogul portugues british french dutch came loot us took',\n",
       " 'yet done nation',\n",
       " 'conquer anyon',\n",
       " 'grab land cultur histori tri enforc way life',\n",
       " '',\n",
       " 'respect freedom first vision freedom',\n",
       " 'believ india got first vision start war independ',\n",
       " 'freedom must protect nurtur build',\n",
       " 'free one respect us',\n",
       " 'second vision india develop',\n",
       " 'fifti year develop nation',\n",
       " 'time see develop nation',\n",
       " 'among top nation world term gdp',\n",
       " 'percent growth rate area',\n",
       " 'poverti level fall',\n",
       " 'achiev global recognis today',\n",
       " 'yet lack see develop nation',\n",
       " 'incorrect',\n",
       " 'third vision',\n",
       " 'india must stand world',\n",
       " 'believ unless india stand world one respect us',\n",
       " 'strength respect strength',\n",
       " 'must strong militari power also econom power',\n",
       " 'must go',\n",
       " 'good fortun work three great mind',\n",
       " 'vikram sarabhai dept',\n",
       " 'space professor satish dhawan succeed brahm prakash father nuclear materi',\n",
       " 'lucki work three close consid great opportun life',\n",
       " 'see four mileston career']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac3fdb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Apply snowball stemmer\n",
    "from nltk.stem import SnowballStemmer\n",
    "snowball_stemmer = SnowballStemmer(language='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "47efc72a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['three vision india',\n",
       " 'year histori peopl world come invad us captur land conquer mind',\n",
       " 'alexand onward greek turk mogul portugues british french dutch came loot us took',\n",
       " 'yet done nation',\n",
       " 'conquer anyon',\n",
       " 'grab land cultur histori tri enforc way life',\n",
       " '',\n",
       " 'respect freedom first vision freedom',\n",
       " 'believ india got first vision start war independ',\n",
       " 'freedom must protect nurtur build',\n",
       " 'free one respect us',\n",
       " 'second vision india develop',\n",
       " 'fifti year develop nation',\n",
       " 'time see develop nation',\n",
       " 'among top nation world term gdp',\n",
       " 'percent growth rate area',\n",
       " 'poverti level fall',\n",
       " 'achiev global recognis today',\n",
       " 'yet lack see develop nation',\n",
       " 'incorrect',\n",
       " 'third vision',\n",
       " 'india must stand world',\n",
       " 'believ unless india stand world one respect us',\n",
       " 'strength respect strength',\n",
       " 'must strong militari power also econom power',\n",
       " 'must go',\n",
       " 'good fortun work three great mind',\n",
       " 'vikram sarabhai dept',\n",
       " 'space professor satish dhawan succeed brahm prakash father nuclear materi',\n",
       " 'lucki work three close consid great opportun life',\n",
       " 'see four mileston career']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "stop_words = set(stopwords.words('english'))\n",
    "sentences = nltk.tokenize.sent_tokenize(paragraph, language='english')\n",
    "for i in range(len(sentences)):\n",
    "    tokens = word_tokenize(sentences[i])\n",
    "    tokens = [t.lower() for t in tokens]\n",
    "    filtered = [t for t in tokens if t.isalpha() and t not in stop_words]\n",
    "    stemmed = [snowball_stemmer.stem(t) for t in filtered]\n",
    "    sentences[i] = ' '.join(stemmed)\n",
    "\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3be4a43f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\vedan/nltk_data...\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "84afe49b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['three visions india',\n",
       " 'years history people world come invade us capture land conquer mind',\n",
       " 'alexander onwards greeks turks moguls portuguese british french dutch come loot us take',\n",
       " 'yet do nation',\n",
       " 'conquer anyone',\n",
       " 'grab land culture history try enforce way life',\n",
       " '',\n",
       " 'respect freedom first vision freedom',\n",
       " 'believe india get first vision start war independence',\n",
       " 'freedom must protect nurture build',\n",
       " 'free one respect us',\n",
       " 'second vision india development',\n",
       " 'fifty years develop nation',\n",
       " 'time see develop nation',\n",
       " 'among top nations world term gdp',\n",
       " 'percent growth rate areas',\n",
       " 'poverty level fall',\n",
       " 'achievements globally recognise today',\n",
       " 'yet lack see develop nation',\n",
       " 'incorrect',\n",
       " 'third vision',\n",
       " 'india must stand world',\n",
       " 'believe unless india stand world one respect us',\n",
       " 'strength respect strength',\n",
       " 'must strong military power also economic power',\n",
       " 'must go',\n",
       " 'good fortune work three great mind',\n",
       " 'vikram sarabhai dept',\n",
       " 'space professor satish dhawan succeed brahm prakash father nuclear material',\n",
       " 'lucky work three closely consider great opportunity life',\n",
       " 'see four milestones career']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = nltk.tokenize.sent_tokenize(paragraph, language='english')\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    tokens = word_tokenize(sentences[i])\n",
    "    tokens = [t.lower() for t in tokens]\n",
    "    filtered = [t for t in tokens if t.isalpha() and t not in stop_words]\n",
    "    lammetized = [lemmatizer.lemmatize(t,pos='v') for t in filtered]\n",
    "    sentences[i] = ' '.join(lammetized)\n",
    "    \n",
    "sentences"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
