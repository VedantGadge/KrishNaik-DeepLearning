{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "106caf71",
   "metadata": {},
   "source": [
    "## __Imbalanced Dataset Handling__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7811ccd",
   "metadata": {},
   "source": [
    "#### Imbalanced dataset will result into a biased model , eg. if we have a binary classification model on a dataset with 1000 datapoints , 900 YES and 100 NO , the model wil be biased towards YES. \n",
    "#### There are two methods to handle this:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bd47fe",
   "metadata": {},
   "source": [
    "### 1- **Up Sampling**\n",
    "#### We increase the no of datapoints of the minority.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5377f152",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "## Setting the random seed , so whenever we use random , the nos. dont change\n",
    "np.random.seed(123) \n",
    "\n",
    "## Create a dataframe with two classes\n",
    "n_samples = 1000\n",
    "class_0_ratio = 0.9\n",
    "n_class_0 = int(n_samples * class_0_ratio)\n",
    "n_class_1 = n_samples - n_class_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3ba86dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(900, 100)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_class_0,n_class_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4a3c301",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create dataframe with imbalanced dataset\n",
    "\n",
    "class_0 = pd.DataFrame({\n",
    "    'feature_1': np.random.normal(loc = 0 , scale = 1 , size = n_class_0),\n",
    "    'feature_2': np.random.normal(loc = 0 , scale = 1 , size = n_class_0),\n",
    "    'target': [0]*n_class_0\n",
    "})\n",
    "\n",
    "class_1 = pd.DataFrame({\n",
    "    'feature_1': np.random.normal(loc = 2 , scale = 1 , size = n_class_1),\n",
    "    'feature_2': np.random.normal(loc = 2 , scale = 1 , size = n_class_1),\n",
    "    'target': [1]*n_class_1\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c26eee0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.concat([class_0,class_1]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "978aaced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "target",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "1f5f5549-0b20-45a7-9a23-e26280a44af2",
       "rows": [
        [
         "0",
         "900"
        ],
        [
         "1",
         "100"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 2
       }
      },
      "text/plain": [
       "target\n",
       "0    900\n",
       "1    100\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "92156aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_minority = df[df['target']==1]\n",
    "df_majority = df[df['target']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "79a84ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "df_minority_upsampled = resample(df_minority, replace=True , #Sample with replacement\n",
    "         n_samples=len(df_majority),\n",
    "         random_state=42\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012f8e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_upsampled = pd.concat([df_majority,df_minority_upsampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0f9ed6a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "target",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "ee5737a5-5671-4948-ad79-370adf40e1b0",
       "rows": [
        [
         "0",
         "900"
        ],
        [
         "1",
         "900"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 2
       }
      },
      "text/plain": [
       "target\n",
       "0    900\n",
       "1    900\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_upsampled['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d9e578",
   "metadata": {},
   "source": [
    "### 2- Down Sampling\n",
    "#### We decrease the no of datapoints of the majority."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e495abf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "target",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "784f57c7-a3b0-49b5-93d6-787e935edec9",
       "rows": [
        [
         "0",
         "900"
        ],
        [
         "1",
         "100"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 2
       }
      },
      "text/plain": [
       "target\n",
       "0    900\n",
       "1    100\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Setting the random seed , so whenever we use random , the nos. dont change\n",
    "np.random.seed(123) \n",
    "\n",
    "## Create a dataframe with two classes\n",
    "n_samples = 1000\n",
    "class_0_ratio = 0.9\n",
    "n_class_0 = int(n_samples * class_0_ratio)\n",
    "n_class_1 = n_samples - n_class_0\n",
    "\n",
    "## Create dataframe with imbalanced dataset\n",
    "\n",
    "class_0 = pd.DataFrame({\n",
    "    'feature_1': np.random.normal(loc = 0 , scale = 1 , size = n_class_0),\n",
    "    'feature_2': np.random.normal(loc = 0 , scale = 1 , size = n_class_0),\n",
    "    'target': [0]*n_class_0\n",
    "})\n",
    "\n",
    "class_1 = pd.DataFrame({\n",
    "    'feature_1': np.random.normal(loc = 2 , scale = 1 , size = n_class_1),\n",
    "    'feature_2': np.random.normal(loc = 2 , scale = 1 , size = n_class_1),\n",
    "    'target': [1]*n_class_1\n",
    "})\n",
    "\n",
    "df= pd.concat([class_0,class_1]).reset_index(drop=True)\n",
    "\n",
    "df['target'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
